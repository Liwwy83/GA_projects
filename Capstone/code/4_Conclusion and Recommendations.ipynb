{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b61dea",
   "metadata": {},
   "source": [
    "# CAPSTONE - Grade Predictions for A Level H2 Math\n",
    "---\n",
    "# (4) Conclusion and Recommendations\n",
    "In this final notebook, we round up this project by summarizing our results and addressing our objectives brought up in the [Introduction](0_Introduction.ipynb) notebook. We also discussed some limitations we faced and give suggestions for future works.\n",
    "\n",
    "## Contents:\n",
    "- [Model Results vs Benchmark Scores](#Model-Results-vs-Benchmark-Scores)\n",
    "- [Objectives](#Objectives)\n",
    "- [Limitations and Future Works](#Limitations-and-Future-Works)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268e1188",
   "metadata": {},
   "source": [
    "# Model Results vs Benchmark Scores\n",
    "The best results were achieved using Logistic Regression with just the top 3 features of Math Prelim marks, Math C1 marks and Prelim overall points. The results are comparable to benchmark but unfortunately did not achieve 100% recall for ESU. This may be purely by chance and the benchmark method may meet the same issue if carried out on other batches, as we only have limited data on 3 batches.\n",
    "\n",
    "|Batch|Model|Weighted Cohen's Kappa|Recall for ESU|Macro Average Recall|Number Predicted as ESU|\n",
    "|---|---|---|---|---|---|\n",
    "|18|Logistic Regression|0.7681|1.0|0.5431|36|\n",
    "|18|Benchmark|0.7581|1.0|0.5729|19|\n",
    "|19|Logistic Regression|0.7130|1.0|0.5150|24|\n",
    "|19|Benchmark|0.7204|1.0|0.5099|38|\n",
    "|20|Logistic Regression|0.7876|0.8235|0.5216|25|\n",
    "|20|Benchmark|0.7768|1.0|0.5482|35|\n",
    "\n",
    "The Logistic Regression models perform similarly to the benchmarks at predicting grades correctly but are more optimistic as more of the predictions end up better than the actual grade.\n",
    "\n",
    "|Batch|Model|Correct Predictions|Within 1 Grade|2 or More Grades Away|Better Than Actual|Worse Than Actual|\n",
    "|---|---|---|---|---|---|---|\n",
    "|18|Logistic Regression|82.3%|97.0%|3.0%|9.9%|7.7%|\n",
    "|18|Benchmark|81.0%|97.5%|2.5%|9.1%|9.9%|\n",
    "|19|Logistic Regression|78.4%|96.6%|3.4%|12.0%|9.6%|\n",
    "|19|Benchmark|77.6%|95.9%|4.1%|10.3%|12.1%|\n",
    "|20|Logistic Regression|80.4%|97.3%|2.7%|12.4%|7.1%|\n",
    "|20|Benchmark|80.7%|97.3%|2.7%|10.1%|9.1%|\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e921d9",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "We have 3 objectives raised in the [Introduction](0_Introduction.ipynb) notebook and we achieved the first 2 objectives.\n",
    "\n",
    "## Objective 1\n",
    "Evaluate the effectiveness of a benchmark method using only Prelim marks and past years' results that does not involve machine learning.\n",
    "\n",
    "The [benchmark](1_Benchmark.ipynb) method was found to be highly effective, with weighted kappa scores between 0.7 and 0.8, which is similar to what our best model could achieve. In addition, most of the 62 features created in our [Data Cleaning and EDA](2_Data_Cleaning_and_EDA.ipynb) notebook end up not being used, with Prelim marks being a very strong predictor by itself.\n",
    "\n",
    "We highly recommend schools to implement this method systematically so that teachers need not look through each and every one of their dozens of students exam results to give a prediction. This will lighten the teachers' workload and the whole cohort will be given fairer predictions that do not depend on individual teachers' biases. The school could then give teachers the option of modifying the predicted grade manually if they desire.\n",
    "\n",
    "If the school wishes to give more optimistic predictions to the students, they may adopt the Logistic Regression model used to give final predictions in the [Modelling](3_Modelling.ipynb) notebook. However, the model developed here is specific to only this subject for this particular school and predictions for other subjects or other schools will require appropriate data cleaning and modelling to be done.\n",
    "\n",
    "## Objective 2\n",
    "Sieve out factors that help predict use them to generate better predictions, so that the potentially high-achieving students can be given better predicted grades to boost their university and/or scholarship applications.\n",
    "\n",
    "From the [Modelling](3_Modelling.ipynb) notebook, we found that most features were not important and adding more features only caused the model to perform worse. Only 3 features (Math Prelim marks, Math C1 marks and Prelim overall points) are used in the final model, while other features such as CCA involvement that we hypothesized may be important in our [Introduction](0_Introduction.ipynb) turned out to not have significant impact on the final A level grade.\n",
    "\n",
    "However, our model does achieve the aim of giving better predicted grades than the benchmark method as a higher proportion of students ended up with predicted grade better than actual grade.\n",
    "\n",
    "In addition, we found that students who take H2 Chemistry have a higher chance of getting 'A' compared to students who do not, and similarly male students have higher chance of getting 'A' compared to female students if all other features are held constant. For students at the boundary of grade 'A' and grade 'B', we recommend that teachers focus more on the female students who do not take H2 Chemistry to help push her to an 'A' grade for Math A level.\n",
    "\n",
    "\n",
    "## Objective 3\n",
    "Reduce the number of students in the watchlist so that teachers can focus more attention on the true potential weak performers.\n",
    "\n",
    "This objective was not met. Even though our final model only put 25 students on the watchlist compared to the benchmark method for batch 20 that highlighted 35 students, it did not capture 100% of the students in the lowest grade category.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35e8fd9",
   "metadata": {},
   "source": [
    "# Limitations and Future Works\n",
    "We were limited to just 2 batches of students for creating our machine learning models and 1 batch for final testing. Results could plausibly be improved with more batches of data.\n",
    "\n",
    "We were also limited to the information that we could get. For example, we wanted to consider home-school distance, as we hypothesized that a further distance may mean more time in transit and less time for studying, leading to poorer results, but we were not granted the information due to confidentiality. We also wanted to try natural language processing on form teachers' comments, but were told that these comments usually included the students' names and would be difficult to mask before passing to us.\n",
    "\n",
    "For future works, we could consider making predictions for other subjects. A top choice will be General Paper, which is taken by almost every A level student. It is likely more challenging to get predictions as good as the ones for Mathematics because General Paper is a writing subject that could be more subjective depending on the marker and whether the student picked a right topic for the essay."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
